# AgentÂ â€“ A Selfâ€‘Modifying, Pydanticâ€‘AIâ€‘Driven Code Assistant

> **Status:** Proofâ€‘ofâ€‘concept skeleton | **Type safety:** `mypy --strict` clean | **License:** MIT  

**Agent** is a pureâ€‘Python **libraryÂ +Â CLI** that embeds a large Python codeâ€‘base into an inâ€‘process vector store and drives an âœ¨ *intelligent refactoring loop* âœ¨ powered by [PydanticÂ AI](https://docs.pydantic.dev/pydantic-ai/).  
It ships *batteriesâ€‘included*: deterministic offline embeddings, JSONâ€‘persisted vector DB, and test / typeâ€‘check runners â€“ all installable from GitHub with **no nonâ€‘Python services**.

---

## Tableâ€¯ofâ€¯Contents
1. [Features](#features)  
2. [Architecture](#architecture)  
3. [Installation](#installation)  
4. [QuickÂ Start](#quick-start)  
   1. [CLI workflow](#cli-workflow)  
   2. [PythonÂ API](#python-api)  
5. [How ItÂ Works](#how-it-works)  
6. [Configuration](#configuration)  
7. [Extending](#extending)  
8. [Development](#development)  
9. [Docker](#docker)  
10. [FAQ](#faq)

---

## Features

| Capability                                   | Outâ€‘ofâ€‘box? | Notes |
|----------------------------------------------|-------------|-------|
| Semantic code search (vector RAG)            | âœ…          | Inâ€‘process JSON vector store (swap to Chroma later). |
| Offline deterministic embeddings             | âœ…          | Hashâ€‘based; swapâ€‘in OpenAI easily. |
| CLI commands (`index`, `refactor`)           | âœ…          | Oneâ€‘liners for daily work. |
| Interactive agent via Python API             | âœ…          | `agent.chat_sync(...)`. |
| Testâ€‘driven validation (`pytest`)            | âœ…          | Returns pass/fail + logs. |
| Static typing enforcement (`mypy`)           | âœ…          | `--strict` passes itself. |
| File read/write tools with autoâ€‘reâ€‘indexing  | âœ…          | No stale vectors. |
| Polling fileâ€‘watcher for external edits      | âœ…          | Optional; pureâ€‘Python. |
| MCP clients (Git, Filesystem, Runâ€‘Python)    | ðŸ…¾ stub     | Interfaces defined; plug servers later. |
| Real LLM & embeddings (OpenAI)               | ðŸ…¾ stub     | Provide API key & swap embedder. |

---

## Architecture

```
src/agent
â”‚
â”œâ”€ config.py        â† Central typed settings
â”œâ”€ main.py          â† Agent factory & tool registry
â”‚
â”œâ”€ embeddings/      â† Chunker, hashâ€‘embeddings, JSON vector DB
â”œâ”€ tools/           â† LLMâ€‘callable helpers (search, tests, mypy, exec, IO)
â”œâ”€ watcher/         â† Optional polling FS watcher
â”‚
â”œâ”€ cli/             â† Typer CLI  (entryâ€‘point: `agent`)
â””â”€ gui/             â† Minimal FastAPI stub (future AGâ€‘UI)
```

Every module is implemented and passes `mypy --strict`; only the optional MCP
clients remain `NotImplementedError`.

---

## Installation

### Quick install (pip + GitHub)

```bash
pip install "git+https://github.com/Tuee22/agent.git#egg=agent"
```

### Editable clone (recommended for hacking)

```bash
git clone https://github.com/Tuee22/agent.git
cd agent
pip install -e ".[dev]"          # or: poetry install --with dev
```

Optional sanity check:

```bash
pytest -q                  # unit tests
mypy --strict src tests    # type safety
```

---

## QuickÂ Start

Assume your project lives in `~/projects/acme/`.

### CLIÂ workflow

```bash
cd ~/projects/acme               # target repo

# 1ï¸âƒ£ build/refresh local vector index (oneâ€‘time)
agent index

# 2ï¸âƒ£ refactor a module to async I/O
agent refactor --module src/data_processing.py                --objective "convert blocking I/O to asyncio and clarify naming"
```

What happens:

1. Agent retrieves semantic context for the file.  
2. LLM proposes an async refactor patch.  
3. File is written **and reâ€‘indexed**.  
4. `pytest` and `mypy --strict` run; results printed.

### PythonÂ API

```python
from agent import get_agent

agent = get_agent()

prompt = """ 
Refactor 'src/data_processing.py':
â€¢ Replace synchronous HTTP with aiohttp
â€¢ Ensure unit tests and static types pass
"""
reply = agent.chat_sync(prompt)
print(reply.message.content)

# Examine individual tool calls
for call in reply.tool_calls:
    print(call.tool_name, "=>", call.output_summary)
```

---

## How ItÂ Works

1. **Embedding index**  
   * Files â†’ 400â€‘line chunks â†’ 128â€‘D hash embeddings.  
   * Stored with lineâ€‘range metadata in `.agent/chroma/vectors.jsonl`.  
2. **Tools**  
   * `read_file` / `write_file` (write triggers reâ€‘embedding).  
   * `code_search` performs cosine search for RAG context.  
   * `run_tests` executes `pytest`; `run_mypy` enforces `mypy --strict`.  
3. **Agent loop**  
   * PydanticÂ AIâ€™s LLM decides which tool to call next; results feed back.  
4. **Consistency**  
   * Polling watcher (optional) reâ€‘embeds files touched outside the agent.

---

## Configuration

Environment variables (`AGENT_*`) override defaults:

| Variable                  | Default               | Purpose |
|---------------------------|-----------------------|---------|
| `AGENT_PROJECT_ROOT`      | `.`                   | Repo root to index. |
| `AGENT_CHROMA_DIR`        | `.agent/chroma`       | Persistence folder. |
| `AGENT_MODEL_NAME`        | `gpt-4o-mini`         | LLM choice. |
| `AGENT_EMBEDDINGS_MODEL`  | `gpt-embeddings-mini` | (if using OpenAI). |
| `AGENT_OPENAI_API_KEY`    | _empty_               | Enable real embeddings/LLM. |

Switch to OpenAI embeddings:

```python
from openai import OpenAI
from agent.embeddings.indexer import EmbeddingClient

class OpenAIClient(EmbeddingClient):
    def __init__(self, key: str) -> None:
        self._client = OpenAI(api_key=key)

    def embed(self, text: str) -> list[float]:
        rsp = self._client.embeddings.create(
            input=text, model="text-embedding-3-small"
        )
        return rsp.data[0].embedding
```

Pass an `OpenAIClient` wherever `HashEmbeddingClient` is used.

---

## Extending

* **VectorÂ DB** â€“ implement `VectorStore` using Chroma/FAISS.  
* **MCP servers** â€“ finish stubs in `agent/mcp/` to integrate Git, FS, etc.  
* **New tools** â€“ add typed function in `agent/tools/`, register it in `agent/main.py`.  
* **GUI** â€“ expand `agent/gui/app.py` with a PydanticÂ AI AGâ€‘UI or Streamlit.

---

## Development

```bash
poetry install --with dev
pytest -q
mypy --strict src tests
black --check src tests
```

### Contribution Guidelines

* No `Any` or `# type: ignore` in committed code.  
* Public functions/classes are documented.  
* Aim for >â€¯90â€¯% test coverage.

---

## Docker

```bash
docker compose -f docker/docker-compose.yaml up --build
```

Starts **JupyterLab** at <http://localhost:9999>; host repo is mounted at `/workspace`.

---

## FAQ

<details>
<summary><strong>Does it really modify my files?</strong></summary>

Yes. The agent writes directly to your working tree after the LLM chooses a diff
and validations pass. Always commit or back up firstâ€”or run it on a branch.
</details>

<details>
<summary><strong>How large a codeâ€‘base can it handle?</strong></summary>

The bundled JSON vector store scales comfortably to ~100â€¯kÂ LOC.  
For monorepos swap to Chroma or another ANN engine.
</details>

<details>
<summary><strong>Why use hashâ€‘based embeddings by default?</strong></summary>

It keeps the project 100â€¯% offline, free, and deterministic. Real embeddings are one `EmbeddingClient` away.
</details>

<details>
<summary><strong>Is the agent asynchronous?</strong></summary>

Current tools are synchronous; PydanticÂ AI supports async if you need it.
</details>

---

*Happy hackingÂ â€” and remember: typeâ€‘safety first, hallucinations secondÂ ðŸ˜‰*
